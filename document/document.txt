------------------------
注意事項

hotels.csv変更後python再起動

------------------------
動作方法

# crontablに下記を設定
crontab -e
*/10 * * * cd /home/ec2-user/bot/v2/bat; /home/ec2-user/.pyenv/shims/python /home/ec2-user/bot/v2/bat/main_daily.py

# 下記を実行
nohup python -u main_crawler.py &
nohup python -u main_scraping.py &

------------------------
動作の流れ

・main_crawler.py
毎日00時から取得開始、03時頃までには終わる予定。
対象のホテル(config/hotels.csv)を毎日巡回してデータをplansに保存します。
対象ホテルの本日～60日、人数1～4 でパラメーターを変え取得。
取得したページを data/本日/file/ 以下に保存します。

・main_scraping.py
date/本日/file/ 以下にあるファイルを存在確認し、ファイルがある場合plansにデータを保存します。

・main_daily.py(cron)
plansの内容をplans_searchにinsertします。
plansの内容をplans_allにinsertします。
plansをtruncateします。

・crawler_checker
データ取得チェック用プログラム集

main_clear.py
data 以下にあるファイルをくりあします。

main_crawler.py
data にクロールしてファイルを保存します。1ホテル1ページのみ。

main_scraping.py
dataにあるファイルをscrapingします。
successの場合 data/success にファイル移動

main_sing.py
解析失敗ファイル(data/successに移動しないファイル)を指定してチェック

------------------------
DB

tableは下記の3つを同じ構造で作成
・tmp クロール中のデータ、scrapingでinsert
・plans_all すべてのデータが入る
・plans 検索用 検索分のみのデータが入る

※ plans には当日分のデータしか入れない、検索対象は最新のデータのみとなるため

・各テーブルのindex
tmp以外はtmpをもとにinsertするためauto_incrementは外す
tmpは下記を外す
create fulltext index tmp_full_text
    on tmp (full_text);
